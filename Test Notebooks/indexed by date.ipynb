{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a900f3-b8c4-4ce8-9f28-016fb57e0867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: statsmodels in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (0.14.1)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (from statsmodels) (24.0)\n",
      "Requirement already satisfied: six in /Users/Arya/opt/anaconda3/lib/python3.8/site-packages (from patsy>=0.5.4->statsmodels) (1.15.0)\n",
      "Downloading pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tzdata, python-dateutil, pandas\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.9.1 requires ruamel-yaml, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "spyder 4.2.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.0.3 python-dateutil-2.9.0.post0 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas statsmodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import RFECV, mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24ddf4d-7e39-430a-a688-c9935770730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38130, 32)\n",
      "(38130, 31)\n"
     ]
    }
   ],
   "source": [
    "#Importing Data\n",
    "data = pd.read_csv(\"data/ACLED2021-2024.csv\")\n",
    "print(data.shape)\n",
    "data['event_date'] = pd.to_datetime(data['event_date'], errors='coerce')\n",
    "data.set_index('event_date', inplace=True)\n",
    "#data.index = pd.to_datetime(data.index)\n",
    "print(data.shape)\n",
    "\n",
    "data.drop(columns=['time_precision', 'assoc_actor_1', 'assoc_actor_2', 'iso', 'region', 'admin3', 'location', \n",
    "                  'latitude', 'longitude', 'geo_precision', 'source_scale', 'timestamp', 'tags', 'population_best', 'event_id_cnty'], \n",
    "          inplace=True)\n",
    "#data = data.dropna(subset=['event_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00346cb",
   "metadata": {},
   "source": [
    "38130 rows × 32 columns - Original Dataset Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb555263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 40 duplicates\n",
      "(38090, 16)\n"
     ]
    }
   ],
   "source": [
    "# Dropping Dupes\n",
    "initial_row_count = data.shape[0]\n",
    "data = data.drop_duplicates()\n",
    "final_row_count = data.shape[0]\n",
    "print(f\"Removed {initial_row_count - final_row_count} duplicates\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be98795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                  0\n",
      "disorder_type         0\n",
      "event_type            0\n",
      "sub_event_type        0\n",
      "actor1                0\n",
      "inter1                0\n",
      "actor2                0\n",
      "inter2                0\n",
      "interaction           0\n",
      "civilian_targeting    0\n",
      "country               0\n",
      "admin1                0\n",
      "admin2                0\n",
      "source                0\n",
      "notes                 0\n",
      "fatalities            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Reformatting / Cleaning\n",
    "\n",
    "#Addressing NA values - Categorical, NUmerical and date\n",
    "categorical_columns = ['disorder_type', 'event_type', 'sub_event_type', 'actor1', 'actor2', 'civilian_targeting', \n",
    "                       'country', 'admin1', 'admin2', 'source', 'notes']\n",
    "categorical_columns = data[categorical_columns]\n",
    "\n",
    "\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].fillna('Not specified')\n",
    "\n",
    "numerical_columns = ['fatalities', 'inter1', 'inter2', 'interaction']\n",
    "\n",
    "for column in numerical_columns:\n",
    "    data[column] = data[column].fillna(data[column].median()) #using median to fill\n",
    "    \n",
    "print(data.isna().sum())\n",
    "#data.loc[:, 'actor2'] = data['actor2'].fillna('Not specified')\n",
    "#data.loc[:, 'civilian_targeting'] = data['civilian_targeting'].fillna('Not specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7708269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Together Actor1 and 2\n",
    "def consolidate_names(name):\n",
    "    if 'Military Forces of Israel' in name:\n",
    "        return 'Military Forces of Israel'\n",
    "    elif 'Police Forces of Israel' in name:\n",
    "        return 'Police Forces of Israel'\n",
    "    elif 'Hamas Movement' in name:\n",
    "        return 'Hamas Movement'\n",
    "    elif 'Police Forces of Israel' in name or 'Government of Israel' in name:\n",
    "        return 'Government and Police Forces of Israel'\n",
    "    elif 'Police Forces of Palestine' in name or 'Government of Palestine' in name:\n",
    "        return 'Government and Police Forces of Palestine'\n",
    "    elif 'PIJ:' in name or 'Islamic Jihad' in name:\n",
    "        return 'Palestinian Islamic Jihad'\n",
    "    elif 'Hezbollah' in name:\n",
    "        return 'Hezbollah'\n",
    "    elif 'Al Aqsa' in name:\n",
    "        return 'Al Aqsa Martyrs Brigade'\n",
    "    elif 'Katibat' in name:\n",
    "        return 'Katibat Groups (Palestine)'\n",
    "    elif 'PFLP:' in name:\n",
    "        return 'Popular Front for the Liberation of Palestine'\n",
    "    elif 'DFLP:' in name:\n",
    "        return 'Democratic Front for the Liberation of Palestine'\n",
    "    elif 'Military Forces of Iran' in name:\n",
    "        return 'Iranian Revolutionary Guard Corps'\n",
    "    elif 'Islamic State' in name:\n",
    "        return 'Islamic State'\n",
    "#civilians\n",
    "    elif 'Civilians' in name:\n",
    "        if 'Israel' in name or 'Palestine' in name:\n",
    "            return name  #Keeping isr and pal civilians\n",
    "        else:\n",
    "            return 'Civilians (International)'  # grouping others as int.\n",
    "#armed groups\n",
    "    elif 'Unidentified Armed Group' in name:\n",
    "        if 'Israel' in name or 'Palestine' in name:\n",
    "            return name  \n",
    "        else:\n",
    "            return 'Unidentified Armed Group (International)'\n",
    "#military forces\n",
    "    elif 'Military Forces of' in name:\n",
    "        if 'Israel' in name or 'Palestine' in name:\n",
    "            return name  \n",
    "        else:\n",
    "            return 'Military Forces of International Forces'\n",
    "    elif 'Settlers' in name:\n",
    "        return 'Settlers (Israel)'\n",
    "    elif 'Protesters' in name or 'Rioters' in name:\n",
    "        return name  # Retains specific categories due to their distinct contexts\n",
    "    else:\n",
    "        return name #'Other Groups' \n",
    "\n",
    "# Apply the consolidation function to both actor1 and actor2\n",
    "data['actor1_grouped'] = data['actor1'].apply(consolidate_names)\n",
    "data['actor2_grouped'] = data['actor2'].apply(consolidate_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44703ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping smaller entities\n",
    "actor1_counts = data['actor1_grouped'].value_counts()\n",
    "actor2_counts = data['actor2_grouped'].value_counts()\n",
    "\n",
    "def consolidate_small_groups(name, counts): #Check if Isr or Pal if not 'name'\n",
    "    if counts[name] < 10:\n",
    "        if 'Israel' in name:\n",
    "            return 'Other (Israel)'\n",
    "        elif 'Palestine' in name:\n",
    "            return 'Other (Palestine)'\n",
    "        else:\n",
    "            return'Other Group'\n",
    "    else:\n",
    "        # Return the name if the count is 10 or more\n",
    "        return name\n",
    "\n",
    "# Apply the consolidation function to both actor1_grouped and actor2_grouped\n",
    "data['actor1_grouped'] = data['actor1_grouped'].apply(lambda x: consolidate_small_groups(x, actor1_counts))\n",
    "data['actor2_grouped'] = data['actor2_grouped'].apply(lambda x: consolidate_small_groups(x, actor2_counts))\n",
    "\n",
    "\n",
    "# Print the new value counts to confirm re-categorization\n",
    "#print(data['actor1_grouped'].value_counts())\n",
    "#print(data['actor2_grouped'].value_counts())\n",
    "\n",
    "data['actor1'] = data['actor1_grouped']\n",
    "data['actor2'] = data['actor2_grouped']\n",
    "\n",
    "data.drop(['actor1_grouped', 'actor2_grouped'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63144a-e344-4944-bf61-80400d2e220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531726a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73916dad-fec4-4d99-8fba-7cbd785c9c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64024281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf9869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                  0\n",
      "disorder_type         0\n",
      "event_type            0\n",
      "sub_event_type        0\n",
      "actor1                0\n",
      "inter1                0\n",
      "actor2                0\n",
      "inter2                0\n",
      "interaction           0\n",
      "civilian_targeting    0\n",
      "country               0\n",
      "admin1                0\n",
      "admin2                0\n",
      "source                0\n",
      "notes                 0\n",
      "fatalities            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adddd8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of zeros in each column:\n",
      "inter2        27.274875\n",
      "fatalities    91.047519\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of zero values per column\n",
    "zero_counts = (data == 0).astype(int).sum(axis=0)\n",
    "zero_percentage = 100 * zero_counts / len(data)\n",
    "\n",
    "# Display columns with high percentages of zeros\n",
    "print(\"Percentage of zeros in each column:\")\n",
    "print(zero_percentage[zero_percentage > 0])  # Adjust the threshold as necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820657ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Temporal Features for T-S\n",
    "\n",
    "#Date related\n",
    "data['year'] = data.index.year\n",
    "data['month'] = data.index.month\n",
    "data['day'] = data.index.day\n",
    "data['day_of_week'] = data.index.day_name()\n",
    "data['days_since_start'] = (data.index - data.index.min()).days\n",
    "\n",
    "# time since last event of the same type\n",
    "data['time_since_last_event'] = data.groupby('event_type')['days_since_start'].diff()\n",
    "#data['time_since_last_event'] = data.groupby('event_type').apply(lambda x: x.index.to_series().diff().dt.days).reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "# time since last disorder of the same type\n",
    "data['time_since_last_disorder'] = data.groupby('disorder_type')['days_since_start'].diff()\n",
    "#data['time_since_last_disorder'] = data.groupby('disorder_type').apply(lambda x: x.index.to_series().diff().dt.days).reset_index(level=0, drop=True)\n",
    "#print(data[['time_since_last_event', 'time_since_last_disorder']].head())\n",
    "\n",
    "\n",
    "# rolling avg for fatalities\n",
    "data['rolling_avg_fatalities_7d'] = data.groupby(\n",
    "    'event_type')['fatalities'].transform(lambda x: x.rolling(window=7, min_periods=1).mean())\n",
    "\n",
    "\n",
    "# cumulative counts of events and fatalities by specific features\n",
    "data['cumulative_events'] = data.groupby(['event_type']).cumcount() + 1\n",
    "data['cumulative_fatalities'] = data.groupby(['event_type'])['fatalities'].cumsum()\n",
    "\n",
    "log_data = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90cb5424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Arya/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/Arya/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/Arya/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/Arya/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Log transformations\n",
    "log_columns = ['fatalities', 'cumulative_events', 'cumulative_fatalities', 'rolling_avg_fatalities_7d', \n",
    "               'time_since_last_event', 'time_since_last_disorder', 'days_since_start']\n",
    "for col in log_columns:\n",
    "    log_data['log_' + col] = np.log1p(log_data[col])\n",
    "\n",
    "# Creating lagged features\n",
    "for col in log_columns:\n",
    "    log_col = 'log_' + col\n",
    "    for lag in [1, 2, 3]:\n",
    "        log_data[f'{log_col}_lag{lag}'] = log_data[log_col].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cbab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>disorder_type</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sub_event_type</th>\n",
       "      <th>actor1</th>\n",
       "      <th>inter1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>inter2</th>\n",
       "      <th>interaction</th>\n",
       "      <th>civilian_targeting</th>\n",
       "      <th>...</th>\n",
       "      <th>log_rolling_avg_fatalities_7d_lag3</th>\n",
       "      <th>log_time_since_last_event_lag1</th>\n",
       "      <th>log_time_since_last_event_lag2</th>\n",
       "      <th>log_time_since_last_event_lag3</th>\n",
       "      <th>log_time_since_last_disorder_lag1</th>\n",
       "      <th>log_time_since_last_disorder_lag2</th>\n",
       "      <th>log_time_since_last_disorder_lag3</th>\n",
       "      <th>log_days_since_start_lag1</th>\n",
       "      <th>log_days_since_start_lag2</th>\n",
       "      <th>log_days_since_start_lag3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-19</th>\n",
       "      <td>2024</td>\n",
       "      <td>Political violence</td>\n",
       "      <td>Explosions/Remote violence</td>\n",
       "      <td>Shelling/artillery/missile attack</td>\n",
       "      <td>Hamas Movement</td>\n",
       "      <td>3</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-19</th>\n",
       "      <td>2024</td>\n",
       "      <td>Demonstrations</td>\n",
       "      <td>Protests</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>Protesters (Israel)</td>\n",
       "      <td>6</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-19</th>\n",
       "      <td>2024</td>\n",
       "      <td>Demonstrations</td>\n",
       "      <td>Riots</td>\n",
       "      <td>Violent demonstration</td>\n",
       "      <td>Rioters (Israel)</td>\n",
       "      <td>5</td>\n",
       "      <td>Rioters (Israel)</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-19</th>\n",
       "      <td>2024</td>\n",
       "      <td>Demonstrations</td>\n",
       "      <td>Protests</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>Protesters (Israel)</td>\n",
       "      <td>6</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>6.999422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-19</th>\n",
       "      <td>2024</td>\n",
       "      <td>Political violence</td>\n",
       "      <td>Battles</td>\n",
       "      <td>Armed clash</td>\n",
       "      <td>Hezbollah</td>\n",
       "      <td>3</td>\n",
       "      <td>Military Forces of Israel</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>6.999422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-20</th>\n",
       "      <td>2021</td>\n",
       "      <td>Strategic developments</td>\n",
       "      <td>Strategic developments</td>\n",
       "      <td>Other</td>\n",
       "      <td>Military Forces of Israel</td>\n",
       "      <td>8</td>\n",
       "      <td>Civilians (Palestine)</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-20</th>\n",
       "      <td>2021</td>\n",
       "      <td>Political violence</td>\n",
       "      <td>Riots</td>\n",
       "      <td>Mob violence</td>\n",
       "      <td>Rioters (Israel)</td>\n",
       "      <td>5</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-20</th>\n",
       "      <td>2021</td>\n",
       "      <td>Demonstrations</td>\n",
       "      <td>Protests</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>Protesters (Palestine)</td>\n",
       "      <td>6</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-20</th>\n",
       "      <td>2021</td>\n",
       "      <td>Political violence</td>\n",
       "      <td>Riots</td>\n",
       "      <td>Mob violence</td>\n",
       "      <td>Rioters (Israel)</td>\n",
       "      <td>5</td>\n",
       "      <td>Civilians (Palestine)</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>Civilian targeting</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-20</th>\n",
       "      <td>2021</td>\n",
       "      <td>Strategic developments</td>\n",
       "      <td>Strategic developments</td>\n",
       "      <td>Looting/property destruction</td>\n",
       "      <td>Hamas Movement</td>\n",
       "      <td>3</td>\n",
       "      <td>Military Forces of Israel</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38090 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            year           disorder_type                  event_type  \\\n",
       "event_date                                                             \n",
       "2024-04-19  2024      Political violence  Explosions/Remote violence   \n",
       "2024-04-19  2024          Demonstrations                    Protests   \n",
       "2024-04-19  2024          Demonstrations                       Riots   \n",
       "2024-04-19  2024          Demonstrations                    Protests   \n",
       "2024-04-19  2024      Political violence                     Battles   \n",
       "...          ...                     ...                         ...   \n",
       "2021-04-20  2021  Strategic developments      Strategic developments   \n",
       "2021-04-20  2021      Political violence                       Riots   \n",
       "2021-04-20  2021          Demonstrations                    Protests   \n",
       "2021-04-20  2021      Political violence                       Riots   \n",
       "2021-04-20  2021  Strategic developments      Strategic developments   \n",
       "\n",
       "                               sub_event_type                     actor1  \\\n",
       "event_date                                                                 \n",
       "2024-04-19  Shelling/artillery/missile attack             Hamas Movement   \n",
       "2024-04-19                   Peaceful protest        Protesters (Israel)   \n",
       "2024-04-19              Violent demonstration           Rioters (Israel)   \n",
       "2024-04-19                   Peaceful protest        Protesters (Israel)   \n",
       "2024-04-19                        Armed clash                  Hezbollah   \n",
       "...                                       ...                        ...   \n",
       "2021-04-20                              Other  Military Forces of Israel   \n",
       "2021-04-20                       Mob violence           Rioters (Israel)   \n",
       "2021-04-20                   Peaceful protest     Protesters (Palestine)   \n",
       "2021-04-20                       Mob violence           Rioters (Israel)   \n",
       "2021-04-20       Looting/property destruction             Hamas Movement   \n",
       "\n",
       "            inter1                     actor2  inter2  interaction  \\\n",
       "event_date                                                           \n",
       "2024-04-19       3              Not specified       0           30   \n",
       "2024-04-19       6              Not specified       0           60   \n",
       "2024-04-19       5           Rioters (Israel)       5           55   \n",
       "2024-04-19       6              Not specified       0           60   \n",
       "2024-04-19       3  Military Forces of Israel       1           13   \n",
       "...            ...                        ...     ...          ...   \n",
       "2021-04-20       8      Civilians (Palestine)       7           78   \n",
       "2021-04-20       5              Not specified       0           50   \n",
       "2021-04-20       6              Not specified       0           60   \n",
       "2021-04-20       5      Civilians (Palestine)       7           57   \n",
       "2021-04-20       3  Military Forces of Israel       8           38   \n",
       "\n",
       "            civilian_targeting  ... log_rolling_avg_fatalities_7d_lag3  \\\n",
       "event_date                      ...                                      \n",
       "2024-04-19       Not specified  ...                                NaN   \n",
       "2024-04-19       Not specified  ...                                NaN   \n",
       "2024-04-19       Not specified  ...                                NaN   \n",
       "2024-04-19       Not specified  ...                                0.0   \n",
       "2024-04-19       Not specified  ...                                0.0   \n",
       "...                        ...  ...                                ...   \n",
       "2021-04-20       Not specified  ...                                0.0   \n",
       "2021-04-20       Not specified  ...                                0.0   \n",
       "2021-04-20       Not specified  ...                                0.0   \n",
       "2021-04-20  Civilian targeting  ...                                0.0   \n",
       "2021-04-20       Not specified  ...                                0.0   \n",
       "\n",
       "           log_time_since_last_event_lag1 log_time_since_last_event_lag2  \\\n",
       "event_date                                                                 \n",
       "2024-04-19                            NaN                            NaN   \n",
       "2024-04-19                            NaN                            NaN   \n",
       "2024-04-19                            NaN                            NaN   \n",
       "2024-04-19                            NaN                            NaN   \n",
       "2024-04-19                            0.0                            NaN   \n",
       "...                                   ...                            ...   \n",
       "2021-04-20                            0.0                           -inf   \n",
       "2021-04-20                            0.0                            0.0   \n",
       "2021-04-20                            0.0                            0.0   \n",
       "2021-04-20                            0.0                            0.0   \n",
       "2021-04-20                            0.0                            0.0   \n",
       "\n",
       "           log_time_since_last_event_lag3 log_time_since_last_disorder_lag1  \\\n",
       "event_date                                                                    \n",
       "2024-04-19                            NaN                               NaN   \n",
       "2024-04-19                            NaN                               NaN   \n",
       "2024-04-19                            NaN                               NaN   \n",
       "2024-04-19                            NaN                               0.0   \n",
       "2024-04-19                            NaN                               0.0   \n",
       "...                                   ...                               ...   \n",
       "2021-04-20                            0.0                               0.0   \n",
       "2021-04-20                           -inf                               0.0   \n",
       "2021-04-20                            0.0                               0.0   \n",
       "2021-04-20                            0.0                               0.0   \n",
       "2021-04-20                            0.0                               0.0   \n",
       "\n",
       "            log_time_since_last_disorder_lag2  \\\n",
       "event_date                                      \n",
       "2024-04-19                                NaN   \n",
       "2024-04-19                                NaN   \n",
       "2024-04-19                                NaN   \n",
       "2024-04-19                                NaN   \n",
       "2024-04-19                                0.0   \n",
       "...                                       ...   \n",
       "2021-04-20                               -inf   \n",
       "2021-04-20                                0.0   \n",
       "2021-04-20                                0.0   \n",
       "2021-04-20                                0.0   \n",
       "2021-04-20                                0.0   \n",
       "\n",
       "            log_time_since_last_disorder_lag3  log_days_since_start_lag1  \\\n",
       "event_date                                                                 \n",
       "2024-04-19                                NaN                        NaN   \n",
       "2024-04-19                                NaN                   6.999422   \n",
       "2024-04-19                                NaN                   6.999422   \n",
       "2024-04-19                                NaN                   6.999422   \n",
       "2024-04-19                                NaN                   6.999422   \n",
       "...                                       ...                        ...   \n",
       "2021-04-20                                0.0                   0.000000   \n",
       "2021-04-20                               -inf                   0.000000   \n",
       "2021-04-20                                0.0                   0.000000   \n",
       "2021-04-20                                0.0                   0.000000   \n",
       "2021-04-20                                0.0                   0.000000   \n",
       "\n",
       "           log_days_since_start_lag2  log_days_since_start_lag3  \n",
       "event_date                                                       \n",
       "2024-04-19                       NaN                        NaN  \n",
       "2024-04-19                       NaN                        NaN  \n",
       "2024-04-19                  6.999422                        NaN  \n",
       "2024-04-19                  6.999422                   6.999422  \n",
       "2024-04-19                  6.999422                   6.999422  \n",
       "...                              ...                        ...  \n",
       "2021-04-20                  0.000000                   0.000000  \n",
       "2021-04-20                  0.000000                   0.000000  \n",
       "2021-04-20                  0.000000                   0.000000  \n",
       "2021-04-20                  0.000000                   0.000000  \n",
       "2021-04-20                  0.000000                   0.000000  \n",
       "\n",
       "[38090 rows x 53 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba2dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(log_data)\n",
    "#print(log_data.isna().sum())\n",
    "\n",
    "# percentage of zero values\n",
    "zero_counts = (log_data == 0).astype(int).sum(axis=0)\n",
    "zero_percentage = 100 * zero_counts / len(log_data)\n",
    "#print(zero_percentage[zero_percentage > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa505f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: 'Political violence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Political violence'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aa5ba507b427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#replacing infinities w median\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlog_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlog_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#forward + backward prop to fill 0's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11621\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11622\u001b[0m         ):\n\u001b[0;32m> 11623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11625\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"median\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11210\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11211\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 11212\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  11213\u001b[0m             \u001b[0;34m\"median\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11214\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11156\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11158\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11159\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11160\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  10517\u001b[0m         \u001b[0;31m# After possibly _get_data and transposing, we are now in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10518\u001b[0m         \u001b[0;31m#  simple case where we can use BlockManager.reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10519\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10520\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mnbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mblk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  10480\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10481\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10482\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10484\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# e.g. \"could not convert string to float: 'a'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: could not convert string to float: 'Political violence'"
     ]
    }
   ],
   "source": [
    "#Cleaning log data\n",
    "\n",
    "#replacing infinities w median\n",
    "log_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "log_data.fillna(log_data.median(), inplace=True)\n",
    "\n",
    "#forward + backward prop to fill 0's \n",
    "log_data['time_since_last_event'].fillna(method='ffill', inplace=True)\n",
    "log_data['time_since_last_event'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "lag_cols = [col for col in log_data.columns if 'log_time_since_last_event' in col or 'lag' in col]\n",
    "log_data[lag_cols] = log_data[lag_cols].fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(log_data)\n",
    "print(log_data.isna().sum())\n",
    "\n",
    "# percentage of zero values\n",
    "zero_counts = (log_data == 0).astype(int).sum(axis=0)\n",
    "zero_percentage = 100 * zero_counts / len(log_data)\n",
    "print(zero_percentage[zero_percentage > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1884450-7fc5-4e80-8606-287c9e9bc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "\n",
    "#One-Hot for Categoricals\n",
    "categorical_cols = ['disorder_type', 'event_type', 'actor1', 'actor2', 'civilian_targeting',\n",
    "                    'country', 'admin1', 'admin2', 'day_of_week']\n",
    "log_data_encoded = pd.get_dummies(log_data, columns=categorical_cols)\n",
    "log_data_encoded\n",
    "\n",
    "#Label Encoder\n",
    "label_encoders = {}\n",
    "\n",
    "for col in ['inter1', 'inter2', 'interaction', 'sub_event_type']:\n",
    "    le = LabelEncoder()\n",
    "    log_data_encoded[col] = le.fit_transform(log_data_encoded[col])\n",
    "    label_encoders[col] = le  # storing the encoder\n",
    "#print(log_data_encoded.isna().sum())\n",
    "log_data_encoded.to_csv('data/log_data_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3500684",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis for numerical cols\n",
    "numerical_cols = log_data_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_data = log_data_encoded[numerical_cols]\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "threshold = 0.85\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mututal Information features\n",
    "\n",
    "target = 'sub_event_type'\n",
    "\n",
    "# taking out the text + datetime\n",
    "features = log_data_encoded.drop(columns=[target,'source', 'notes'])\n",
    "\n",
    "# actual mi score calculation\n",
    "mi_scores = mutual_info_classif(features, log_data_encoded[target], discrete_features='auto')\n",
    "\n",
    "# putting in df\n",
    "mi_df = pd.DataFrame({'Feature': features.columns, 'MI_Score': mi_scores})\n",
    "mi_df.sort_values('MI_Score', ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='MI_Score', y='Feature', data=mi_df.sort_values('MI_Score', ascending=False).head(20))\n",
    "plt.title('Top 20 Features by Mutual Information')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Importance\n",
    "#numeric_encoded_log_data\n",
    "#Dropping numeric + T/T Splitting\n",
    "X = log_data_encoded.drop(['sub_event_type', 'source', 'notes'], axis=1)\n",
    "y = log_data_encoded['sub_event_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# feature importances into df\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "rf_df = pd.DataFrame({'Feature': X_train.columns, 'RF_Importance': importances})\n",
    "rf_df.sort_values('RF_Importance', ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='RF_Importance', y='Feature', data=rf_df.sort_values('RF_Importance', ascending=False).head(20))\n",
    "plt.title('Top 20 Features by Random Forest Importance')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ec33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mi_df.shape)\n",
    "print(rf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbec2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = pd.DataFrame({'Feature': X_train.columns,\n",
    "                                    'RF_Importance': forest.feature_importances_})\n",
    "\n",
    "#merging datasets\n",
    "combined_importances = pd.merge(mi_df, rf_df, on='Feature', how='outer')\n",
    "\n",
    "combined_importances.sort_values(by='MI_Score', ascending=False, inplace=True)\n",
    "\n",
    "combined_importances = pd.merge(mi_df, rf_df, on='Feature', how='outer')\n",
    "\n",
    "#set the amount of feaatures\n",
    "sorted_idx = combined_importances.sort_values(by='MI_Score', ascending=False)['Feature'].head(30)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='MI_Score', y='Feature', data=combined_importances[combined_importances['Feature'].isin(sorted_idx)], \n",
    "            color='blue', label='MI Score')\n",
    "sns.barplot(x='RF_Importance', y='Feature', data=combined_importances[combined_importances['Feature'].isin(sorted_idx)], \n",
    "            color='red', alpha=0.6, label='Random Forest Importance')\n",
    "plt.title('Comparison of Feature Importance by MI and Random Forest')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting arbitrary threshold to see the \"small\" values\n",
    "test_thresh1 = 0.2\n",
    "test_thresh2 = 0.01\n",
    "\n",
    "#mi scores\n",
    "low_mi_features = mi_df[mi_df['MI_Score'] <= test_thresh1]\n",
    "\n",
    "#rf importances\n",
    "low_rf_features = rf_df[rf_df['RF_Importance'] <= test_thresh2]\n",
    "\n",
    "# intersection of low importance features from both\n",
    "test_features = pd.merge(low_mi_features, low_rf_features, on='Feature', how='inner')\n",
    "\n",
    "print(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98508e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI score\n",
    "mi_percentile = 50  # aka keeping top 50%\n",
    "mi_threshold = np.percentile(mi_df['MI_Score'], mi_percentile)\n",
    "#top_mi_features = mi_df[mi_df['MI_Score'] >= mi_threshold]\n",
    "selected_mi_features = mi_df[mi_df['MI_Score'] >= mi_threshold]['Feature'].tolist()\n",
    "#top_mi_features.shape\n",
    "#print(selected_mi_features)\n",
    "\n",
    "# random forest importance\n",
    "rf_percentile = 50  # aka keeping top 50% | top 30% is 43 features\n",
    "rf_threshold = np.percentile(rf_df['RF_Importance'], rf_percentile)\n",
    "#top_rf_features = rf_df[rf_df['RF_Importance'] >= rf_threshold]\n",
    "selected_rf_features = rf_df[rf_df['RF_Importance'] >= \n",
    "                                      rf_threshold]['Feature'].tolist()\n",
    "#top_rf_features.shape\n",
    "#print(selected_rf_features)\n",
    "\n",
    "#Combining into 1\n",
    "selected_features = list(set(selected_mi_features) & set(selected_rf_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912eb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_features_combined = pd.merge(top_mi_features, top_rf_features, on='Feature', how='inner')\n",
    "#print(top_features_combined)\n",
    "#top_features_combined.to_csv('data/top_features_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected Features\n",
    "X_selected = log_data_encoded[selected_features]\n",
    "y = log_data_encoded['sub_event_type']\n",
    "\n",
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, \n",
    "                                                                      stratify=y)\n",
    "\n",
    "#Regular model minus text\n",
    "X = log_data_encoded.drop(['sub_event_type', 'source', 'notes'], axis=1) # 'event_date', \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_forecast(train_data, test_length, window=5):\n",
    "    moving_avg = train_data.rolling(window=window).mean().iloc[-1]\n",
    "    return [moving_avg] * test_length\n",
    "\n",
    "moving_avg_predictions = moving_average_forecast(y_train, len(y_test))\n",
    "moving_avg_accuracy = accuracy_score(y_test, moving_avg_predictions)\n",
    "print(f\"Accuracy of Moving Average Forecast: {moving_avg_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d67ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast_last(train_data):\n",
    "    return train_data.iloc[-1]\n",
    "\n",
    "last_value = naive_forecast_last(y_train)  # Get the last value from the training target\n",
    "predictions = [last_value] * len(y_test)  # Create a list of predictions for the test set\n",
    "\n",
    "# Evaluate the prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of Naïve Forecast: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast_last(train_data):\n",
    "    return train_data.iloc[-1]\n",
    "\n",
    "last_value = naive_forecast_last(y_train)  # Get the last value from the training target\n",
    "predictions = [last_value] * len(y_test)  # Create a list of predictions for the test set\n",
    "\n",
    "# Evaluate the prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of Naïve Forecast: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d53248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Selected \n",
    "\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "tree_classifier.fit(X_selected_train, y_train)\n",
    "\n",
    "tree_predictions = tree_classifier.predict(X_selected_test)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
    "tree_classification_report = classification_report(y_test, tree_predictions)\n",
    "print(f\"Accuracy of Decision Tree Selected: {tree_accuracy:.2f}\")\n",
    "print(tree_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Baseline\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
    "tree_classification_report = classification_report(y_test, tree_predictions)\n",
    "print(f\"Accuracy of Decision Tree Selected: {tree_accuracy:.2f}\")\n",
    "print(tree_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ecfc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Selected\n",
    "\n",
    "logistic_regressor = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "logistic_regressor.fit(X_train, y_train)\n",
    "\n",
    "logistic_predictions = logistic_regressor.predict(X_test)\n",
    "\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_classification_report = classification_report(y_test, logistic_predictions)\n",
    "\n",
    "print(f\"Accuracy of Logistic Regression Baseline: {logistic_accuracy:.2f}\")\n",
    "print(logistic_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Baseline\n",
    "\n",
    "logistic_regressor = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "logistic_regressor.fit(X_selected_train, y_train)\n",
    "\n",
    "logistic_predictions = logistic_regressor.predict(X_selected_test)\n",
    "\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_classification_report = classification_report(y_test, logistic_predictions)\n",
    "\n",
    "print(f\"Accuracy of Logistic Regression Baseline: {logistic_accuracy:.2f}\")\n",
    "print(logistic_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aca2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "#numeric_log_data = log_data_encoded.drop(columns=[target,'source', 'notes'])\n",
    "\n",
    "#def test_stationarity(series):\n",
    " #   result = adfuller(series.dropna(), autolag='AIC') \n",
    "#    return {\"Test Statistic\": result[0], \"p-value\": result[1], \"Critical Values\": result[4]}\n",
    "\n",
    "#results = {column: test_stationarity(numeric_log_data[column]) for column in numeric_log_data.columns}\n",
    "\n",
    "#results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99beb20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VAR model requires all data to be numeric and stationary\n",
    "numeric_log_data = log_data_encoded.drop(columns=[target,'source', 'notes'])\n",
    "\n",
    "# Fit the VAR model\n",
    "model = sm.tsa.VAR(numeric_log_data)\n",
    "results = model.fit(maxlags=15, ic='aic')\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# input = [samples, time steps, features]\n",
    "X_train_scaled = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_scaled = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# LSTM\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=72, validation_data=(X_test_scaled, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef102e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
